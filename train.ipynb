{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melee_dataset import MeleeDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "from torch.distributions import Bernoulli,Normal\n",
    "import matplotlib.pyplot as plt\n",
    "from PolicyNet import PolicyNet\n",
    "import torch.nn.functional as F\n",
    "from Agents.BCAgent import BCAgent\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = MeleeDataset(data_path=\"data/train_mini_515\")\n",
    "train_dataset = MeleeDataset(data_path=\"data/train_mini_100\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Game_20250501T001638.slp with 15927 states and 15927 actions. The cache size is 1.\n",
      "obs_dim: torch.Size([54])\n",
      "act_dim: torch.Size([17])\n"
     ]
    }
   ],
   "source": [
    "print(f\"obs_dim: {train_dataset[0][0].shape}\")\n",
    "print(f\"act_dim: {train_dataset[0][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "obs_dim = train_dataset[0][0].shape[0]\n",
    "act_dim = train_dataset[0][1].shape[0]\n",
    "policy  = PolicyNet(obs_dim, act_dim).to(device)\n",
    "# opt     = optim.Adam(policy.parameters(), lr=1e-3)\n",
    "agent = BCAgent(obs_dim, act_dim, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Game_20250430T013632.slp with 16357 states and 16357 actions. The cache size is 2.\n",
      "Loaded Game_20250430T134932.slp with 14271 states and 14271 actions. The cache size is 3.\n",
      "Loaded Game_20250430T063350.slp with 10702 states and 10702 actions. The cache size is 4.\n",
      "Loaded Game_20250430T110512.slp with 13286 states and 13286 actions. The cache size is 5.\n",
      "Loaded Game_20250430T071642.slp with 13928 states and 13928 actions. The cache size is 6.\n",
      "Loaded Game_20250430T051051.slp with 15510 states and 15510 actions. The cache size is 7.\n",
      "Loaded Game_20250430T115152.slp with 12700 states and 12700 actions. The cache size is 8.\n",
      "Loaded Game_20250430T231954.slp with 12677 states and 12677 actions. The cache size is 9.\n",
      "Loaded Game_20250430T065555.slp with 14492 states and 14492 actions. The cache size is 10.\n",
      "Loaded Game_20250430T081407.slp with 14347 states and 14347 actions. The cache size is 11.\n",
      "Loaded Game_20250429T191041.slp with 7781 states and 7781 actions. The cache size is 12.\n",
      "Loaded Game_20250429T232411.slp with 12990 states and 12990 actions. The cache size is 13.\n",
      "Loaded Game_20250430T144255.slp with 13750 states and 13750 actions. The cache size is 14.\n",
      "Loaded Game_20250430T043527.slp with 16228 states and 16228 actions. The cache size is 15.\n",
      "Loaded Game_20250430T023804.slp with 12516 states and 12516 actions. The cache size is 16.\n",
      "Loaded Game_20250430T221050.slp with 14670 states and 14670 actions. The cache size is 17.\n",
      "Loaded Game_20250501T002109.slp with 8011 states and 8011 actions. The cache size is 18.\n",
      "Loaded Game_20250430T021724.slp with 13189 states and 13189 actions. The cache size is 19.\n",
      "Loaded Game_20250430T121612.slp with 12745 states and 12745 actions. The cache size is 20.\n",
      "Loaded Game_20250430T150242.slp with 13008 states and 13008 actions. The cache size is 21.\n",
      "Loaded Game_20250430T155321.slp with 11388 states and 11388 actions. The cache size is 22.\n",
      "Loaded Game_20250430T020009.slp with 13083 states and 13083 actions. The cache size is 23.\n",
      "Loaded Game_20250430T013300.slp with 12405 states and 12405 actions. The cache size is 24.\n",
      "Loaded Game_20250430T113835.slp with 8121 states and 8121 actions. The cache size is 25.\n",
      "Loaded Game_20250430T083915.slp with 11925 states and 11925 actions. The cache size is 26.\n",
      "Loaded Game_20250430T024454.slp with 14227 states and 14227 actions. The cache size is 27.\n",
      "Loaded Game_20250430T005042.slp with 13347 states and 13347 actions. The cache size is 28.\n",
      "Loaded Game_20250430T055227.slp with 12026 states and 12026 actions. The cache size is 29.\n",
      "Loaded Game_20250430T135335.slp with 9257 states and 9257 actions. The cache size is 30.\n",
      "Loaded Game_20250430T014407.slp with 8519 states and 8519 actions. The cache size is 31.\n",
      "Loaded Game_20250430T032414.slp with 8536 states and 8536 actions. The cache size is 32.\n",
      "Loaded Game_20250430T224705.slp with 11663 states and 11663 actions. The cache size is 33.\n",
      "Loaded Game_20250430T174055.slp with 13384 states and 13384 actions. The cache size is 34.\n",
      "Loaded Game_20250430T064738.slp with 14286 states and 14286 actions. The cache size is 35.\n",
      "Loaded Game_20250429T201436.slp with 13005 states and 13005 actions. The cache size is 36.\n",
      "Loaded Game_20250430T060855.slp with 13924 states and 13924 actions. The cache size is 37.\n",
      "Loaded Game_20250430T145017.slp with 6138 states and 6138 actions. The cache size is 38.\n",
      "Loaded Game_20250430T122709.slp with 12830 states and 12830 actions. The cache size is 39.\n",
      "Loaded Game_20250430T114640.slp with 7386 states and 7386 actions. The cache size is 40.\n",
      "Loaded Game_20250430T102049.slp with 11212 states and 11212 actions. The cache size is 41.\n",
      "Loaded Game_20250430T050749.slp with 10665 states and 10665 actions. The cache size is 42.\n",
      "Loaded Game_20250429T233051.slp with 13252 states and 13252 actions. The cache size is 43.\n",
      "Loaded Game_20250430T122254.slp with 14960 states and 14960 actions. The cache size is 44.\n",
      "Loaded Game_20250429T214345.slp with 13065 states and 13065 actions. The cache size is 45.\n",
      "Loaded Game_20250430T033012.slp with 11860 states and 11860 actions. The cache size is 46.\n",
      "Loaded Game_20250429T210907.slp with 11740 states and 11740 actions. The cache size is 47.\n",
      "Loaded Game_20250430T014928.slp with 5898 states and 5898 actions. The cache size is 48.\n",
      "Loaded Game_20250430T233958.slp with 10995 states and 10995 actions. The cache size is 49.\n",
      "Loaded Game_20250430T131512.slp with 8154 states and 8154 actions. The cache size is 50.\n",
      "Loaded Game_20250501T001214.slp with 15565 states and 15565 actions. The cache size is 51.\n",
      "Loaded Game_20250429T231453.slp with 10448 states and 10448 actions. The cache size is 52.\n",
      "Loaded Game_20250429T191255.slp with 11897 states and 11897 actions. The cache size is 53.\n",
      "Loaded Game_20250430T230522.slp with 13626 states and 13626 actions. The cache size is 54.\n",
      "Loaded Game_20250429T205151.slp with 11410 states and 11410 actions. The cache size is 55.\n",
      "Loaded Game_20250429T235950.slp with 10708 states and 10708 actions. The cache size is 56.\n",
      "Loaded Game_20250430T084524.slp with 10895 states and 10895 actions. The cache size is 57.\n",
      "Loaded Game_20250430T180129.slp with 8724 states and 8724 actions. The cache size is 58.\n",
      "Loaded Game_20250429T195801.slp with 13369 states and 13369 actions. The cache size is 59.\n",
      "Loaded Game_20250430T064019.slp with 15478 states and 15478 actions. The cache size is 60.\n",
      "Loaded Game_20250430T181406.slp with 9764 states and 9764 actions. The cache size is 61.\n",
      "Loaded Game_20250430T142152.slp with 7099 states and 7099 actions. The cache size is 62.\n",
      "Loaded Game_20250429T231232.slp with 8213 states and 8213 actions. The cache size is 63.\n",
      "Loaded Game_20250430T001455.slp with 8644 states and 8644 actions. The cache size is 64.\n",
      "Loaded Game_20250430T011027.slp with 9799 states and 9799 actions. The cache size is 65.\n",
      "Loaded Game_20250430T131212.slp with 10454 states and 10454 actions. The cache size is 66.\n",
      "Loaded Game_20250430T111851.slp with 8116 states and 8116 actions. The cache size is 67.\n",
      "Loaded Game_20250429T221934.slp with 11244 states and 11244 actions. The cache size is 68.\n",
      "Loaded Game_20250430T065141.slp with 14929 states and 14929 actions. The cache size is 69.\n",
      "Loaded Game_20250430T231656.slp with 10332 states and 10332 actions. The cache size is 70.\n",
      "Loaded Game_20250430T041744.slp with 11574 states and 11574 actions. The cache size is 71.\n",
      "Loaded Game_20250430T120301.slp with 10706 states and 10706 actions. The cache size is 72.\n",
      "Loaded Game_20250430T040815.slp with 10376 states and 10376 actions. The cache size is 73.\n",
      "Loaded Game_20250430T173032.slp with 13978 states and 13978 actions. The cache size is 74.\n",
      "Loaded Game_20250430T083245.slp with 11800 states and 11800 actions. The cache size is 75.\n",
      "Loaded Game_20250430T115838.slp with 15494 states and 15494 actions. The cache size is 76.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:58, 118.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Game_20250430T075024.slp with 13711 states and 13711 actions. The cache size is 77.\n",
      "Loaded Game_20250501T000340.slp with 8784 states and 8784 actions. The cache size is 78.\n",
      "Loaded Game_20250430T035054.slp with 9790 states and 9790 actions. The cache size is 79.\n",
      "Loaded Game_20250430T001724.slp with 8446 states and 8446 actions. The cache size is 80.\n",
      "Loaded Game_20250430T093627.slp with 11722 states and 11722 actions. The cache size is 81.\n",
      "Loaded Game_20250501T000951.slp with 8246 states and 8246 actions. The cache size is 82.\n",
      "Loaded Game_20250430T224332.slp with 12456 states and 12456 actions. The cache size is 83.\n",
      "Loaded Game_20250430T163733.slp with 15837 states and 15837 actions. The cache size is 84.\n",
      "Loaded Game_20250430T042403.slp with 12189 states and 12189 actions. The cache size is 85.\n",
      "Loaded Game_20250430T234610.slp with 7291 states and 7291 actions. The cache size is 86.\n",
      "Loaded Game_20250429T200904.slp with 11780 states and 11780 actions. The cache size is 87.\n",
      "Loaded Game_20250430T154348.slp with 8096 states and 8096 actions. The cache size is 88.\n",
      "Loaded Game_20250430T175339.slp with 8921 states and 8921 actions. The cache size is 89.\n",
      "Loaded Game_20250429T222626.slp with 14030 states and 14030 actions. The cache size is 90.\n",
      "Loaded Game_20250429T194831.slp with 11019 states and 11019 actions. The cache size is 91.\n",
      "Loaded Game_20250430T140107.slp with 9232 states and 9232 actions. The cache size is 92.\n",
      "Loaded Game_20250429T222247.slp with 12839 states and 12839 actions. The cache size is 93.\n",
      "Loaded Game_20250501T000611.slp with 12919 states and 12919 actions. The cache size is 94.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:26, 65.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Game_20250430T062735.slp with 12188 states and 12188 actions. The cache size is 95.\n",
      "Loaded Game_20250430T133542.slp with 10869 states and 10869 actions. The cache size is 96.\n",
      "Loaded Game_20250430T171226.slp with 13774 states and 13774 actions. The cache size is 97.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:31, 37.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Game_20250430T220402.slp with 11394 states and 11394 actions. The cache size is 98.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:32, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Game_20250430T003354.slp with 9806 states and 9806 actions. The cache size is 99.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [02:33,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Game_20250501T000214.slp with 4888 states and 4888 actions. The cache size is 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9072it [02:54, 52.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Loss: -22.4876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9072it [00:20, 435.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Loss: -27.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9072it [00:20, 437.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Loss: -119.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(6):\n",
    "    total_loss = 0.0\n",
    "    for i, (states, actions) in tqdm(enumerate(train_loader)):\n",
    "        states = states.to(device)       # [B, obs_dim]\n",
    "        actions = actions.to(device)     # [B] integers in [0…act_dim-1]\n",
    "\n",
    "        loss = agent.train(states, actions)\n",
    "\n",
    "        total_loss += loss * states.shape[0]\n",
    "        losses.append(loss)\n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1} — Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_policy.pth\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(policy.state_dict(), \"trained_policy_distribution_combined.pth\")\n",


    "print(\"Model saved to trained_policy.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
